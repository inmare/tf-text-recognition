{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "import text_extract as text\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_PATH = \"./settings.json\"\n",
    "\n",
    "with open(JSON_PATH) as f:\n",
    "    settings = json.load(f)\n",
    "\n",
    "file_settings = settings[\"file\"]\n",
    "file_names = text.data.get_file_names(file_settings)\n",
    "\n",
    "image_array = []\n",
    "h_crop_array = []\n",
    "v_crop_array = []\n",
    "h_max_size = 0\n",
    "v_max_size = 0\n",
    "\n",
    "for name in file_names:\n",
    "    path = file_settings[\"path\"]\n",
    "    gray_img = text.data.read_image(path, name)\n",
    "\n",
    "    rotate_img = text.extract.set_textbox_horizontally(gray_img, settings)\n",
    "    textbox_img = text.extract.extract_textbox(rotate_img, settings)\n",
    "    enhanced_img = text.extract.enhance_textbox(textbox_img, settings)\n",
    "\n",
    "    char_crop_settings = settings[\"cropPoints\"]\n",
    "    [h_crop_points, h_max] = text.data.get_char_info(enhanced_img, char_crop_settings, mode=\"h\")\n",
    "    [v_crop_points, v_max] = text.data.get_char_info(enhanced_img, char_crop_settings, mode=\"v\")\n",
    "\n",
    "    image_array.append(enhanced_img)\n",
    "\n",
    "    h_crop_array.append(h_crop_points)\n",
    "    v_crop_array.append(v_crop_points)\n",
    "\n",
    "    h_max_size = h_max if h_max > h_max_size else h_max_size\n",
    "    v_max_size = v_max if v_max > v_max_size else v_max_size\n",
    "\n",
    "# plt.imshow(image_array[0][:200, :200])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty data\n",
    "# max size (20, 11)\n",
    "\n",
    "text_len = (len(v_crop_array[0]) - 1) * (len(h_crop_array[0]) - 1)\n",
    "char_array = np.zeros((text_len, v_max_size, h_max_size), dtype=image_array[0].dtype)\n",
    "\n",
    "char_idx = 0\n",
    "for v_idx in range(len(v_crop_array[0]) - 1):\n",
    "    for h_idx in range(len(h_crop_array[0]) - 1):\n",
    "        empty_img = np.zeros((v_max_size, h_max_size), dtype=image_array[0].dtype)\n",
    "        v_start = v_crop_array[0][v_idx]\n",
    "        h_start = h_crop_array[0][h_idx]\n",
    "        v_next = v_crop_array[0][v_idx + 1]\n",
    "        h_next = h_crop_array[0][h_idx + 1]\n",
    "        char_img = image_array[0][v_start:v_next, h_start:h_next]\n",
    "\n",
    "        empty_img[:char_img.shape[0], :char_img.shape[1]] = char_img\n",
    "        char_array[char_idx, :, :] = empty_img\n",
    "        char_idx += 1\n",
    "\n",
    "text_array = make_random_text(1, text_len)\n",
    "\n",
    "# for i in range(20):\n",
    "#     plt.figure(figsize=(0.5, 0.5))\n",
    "#     plt.imshow(char_array[i, :, :])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "X_train_full = char_array\n",
    "y_train_full = text_array\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[v_max_size, h_max_size]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, \n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[keras.metrics.sparse_categorical_accuracy]\n",
    "    )\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, \n",
    "                    validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 헷갈릴 글자 대상들\n",
    "# 0 Γ\n",
    "# 8 Δ\n",
    "# 5 Σ\n",
    "# $ -> § or 직접 폰트 수정\n",
    "#  (공백) Ч\n",
    "# ` §\n",
    "\n",
    "# 절대로 헷갈리지 않을 만한 문자들\n",
    "# 그리스어\n",
    "# Γ Δ Ξ Σ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be683a387f613599acfa5f2904ea86e105e419b0abf42dde19e0d0b9b1440bd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
