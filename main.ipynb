{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-text-recognition\n",
    "\n",
    "간단한 머신러닝을 사용해서 MNIST 사진들을 인식하기.  \n",
    "머신러닝 알고리즘 자체는 너무나 간단한 Sequential API이지만,  \n",
    "해당 알고리즘을 `opencv.js`와 `tensorflow.js`를 통해서 브라우저에 이식하는 것이 최종적인 목표이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import text_extract as text\n",
    "import numpy as np\n",
    "import sk_process\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 읽기 및 글자 분리\n",
    "\n",
    "이 코드에서 사용한 opencv함수들은 다음과 같다.  \n",
    "이때, opencv.js에 없는건 ~~취소선~~처리 되어있다.\n",
    "\n",
    "**process.py**\n",
    "* bitwise_not\n",
    "* threshold\n",
    "* dilate\n",
    "* erode\n",
    "* ~~fastNlMeansDenoising~~\n",
    "* addWeighted\n",
    "* getRotationMatrix2D\n",
    "* warpAffine\n",
    "\n",
    "**data.py**\n",
    "* imread\n",
    "* approxPolyDP\n",
    "* boundingRect\n",
    "* findContours\n",
    "* minAreaRect\n",
    "* ~~boxPoints~~\n",
    "\n",
    "과정에서 핵심적인 `fastNlMeansDenoising`함수가 opencv.js에서 사용이 불가능함에 따라,  \n",
    "다음과 같은 대안을 고려해 볼 수 있다.\n",
    "\n",
    "* `fastNlMeansDenoising`함수 알고리즘을 직접 구현하기: 함수 원리 자체가 간단하긴 한데 직접 구현하려면 시간도 오래걸리고 난이도도 생각보다 높을 것 같다.\n",
    "* 다른 방법으로 이미지의 노이즈를 제거하기: Smoothing계열 필터들을 사용해서 노이즈를 제거한 후 해당 결과를 이전 결과와 비교해 본다.\n",
    "\n",
    "알고리즘에 관해서 아무것도 모르는 나는 그냥 후자를 선택해서 하는게 현명할 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_PATH = \"./settings.json\"\n",
    "\n",
    "with open(JSON_PATH) as f:\n",
    "    settings = json.load(f)\n",
    "\n",
    "file_settings = settings[\"file\"]\n",
    "file_names = text.data.get_file_names(file_settings)\n",
    "\n",
    "image_array = []\n",
    "h_crop_array = []\n",
    "v_crop_array = []\n",
    "h_max_size = 0\n",
    "v_max_size = 0\n",
    "\n",
    "for name in file_names:\n",
    "    path = file_settings[\"path\"]\n",
    "    gray_img = text.data.read_image(path, name)\n",
    "\n",
    "    rotate_img = text.extract.set_textbox_horizontally(gray_img, settings)\n",
    "    textbox_img = text.extract.extract_textbox(rotate_img, settings)\n",
    "    enhanced_img = text.extract.enhance_textbox(textbox_img, settings)\n",
    "\n",
    "    char_crop_settings = settings[\"cropPoints\"]\n",
    "    [h_crop_points, h_max] = text.data.get_char_info(enhanced_img, char_crop_settings, mode=\"h\")\n",
    "    [v_crop_points, v_max] = text.data.get_char_info(enhanced_img, char_crop_settings, mode=\"v\")\n",
    "\n",
    "    image_array.append(enhanced_img)\n",
    "\n",
    "    h_crop_array.append(h_crop_points)\n",
    "    v_crop_array.append(v_crop_points)\n",
    "\n",
    "    h_max_size = h_max if h_max > h_max_size else h_max_size\n",
    "    v_max_size = v_max if v_max > v_max_size else v_max_size\n",
    "\n",
    "# plt.imshow(image_array[0][:200, :200])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastNLDenoise와 Bilaterial필터 비교\n",
    "\n",
    "import cv2\n",
    "\n",
    "raw = text.data.read_image(\"./image/\", \"random-ascii.jpg\")\n",
    "raw = raw[200:300, 200:300]\n",
    "\n",
    "invert = text.process.invert(raw)\n",
    "\n",
    "kernel_size = 3\n",
    "sigma_color = 75\n",
    "sigma_space = 75\n",
    "bilaterial = cv2.bilateralFilter(invert, kernel_size, sigma_color, sigma_space)\n",
    "bi_contrast = text.process.contrast(bilaterial, 16)\n",
    "denoise = text.process.denoise(invert, 30, 7, 21)\n",
    "\n",
    "\n",
    "image_list = [invert, bilaterial, bi_contrast, denoise]\n",
    "name_list = [\"original\", \"bilaterial\", \"bi_contrast\", \"denoise\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(len(image_list)):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image_list[i])\n",
    "    plt.title(name_list[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-image용 이미지 처리 코드\n",
    "scikit image에서 `minAreaRect`함수를 지원하지 않아서 직접 Convex hull과 Rotating calipers 알고리즘을 작성해야 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 변환하기\n",
    "\n",
    "여러 이미지가 input으로 와도 적용이 가능하도록 모듈 수정하기  \n",
    "`Tensorflow.js`에서 어떻게 할지 제일 고민이 많이 되는 부분이다.  \n",
    "JS에는 numpy가 없기 때문에...  \n",
    "가능만 하다면 `Tensorflow.js`의 내장기능을 활용해야 할 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty data\n",
    "\n",
    "text_len = (len(v_crop_array[0]) - 1) * (len(h_crop_array[0]) - 1)\n",
    "char_array = np.zeros((text_len, v_max_size, h_max_size), dtype=image_array[0].dtype)\n",
    "\n",
    "char_idx = 0\n",
    "for v_idx in range(len(v_crop_array[0]) - 1):\n",
    "    for h_idx in range(len(h_crop_array[0]) - 1):\n",
    "        empty_img = np.zeros((v_max_size, h_max_size), dtype=image_array[0].dtype)\n",
    "        v_start = v_crop_array[0][v_idx]\n",
    "        h_start = h_crop_array[0][h_idx]\n",
    "        v_next = v_crop_array[0][v_idx + 1]\n",
    "        h_next = h_crop_array[0][h_idx + 1]\n",
    "        char_img = image_array[0][v_start:v_next, h_start:h_next]\n",
    "\n",
    "        empty_img[:char_img.shape[0], :char_img.shape[1]] = char_img\n",
    "        char_array[char_idx, :, :] = empty_img\n",
    "        char_idx += 1\n",
    "\n",
    "text_array = text.seed_random.make_random_text(1, text_len)\n",
    "\n",
    "# for i in range(20):\n",
    "#     plt.figure(figsize=(0.5, 0.5))\n",
    "#     plt.imshow(char_array[i, :, :])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝\n",
    "\n",
    "와! 텐서플로우! 와! MLP!  \n",
    "날먹이 이렇게 쉽습니다 여러분.  \n",
    "앞에서는 장대하게 데이터 추출한 다음에 정작 머신러닝 코드는 핸즈온 머신러닝 베껴쓰는 이게 진정한 용두사미 아닐까...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 사용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "X_train_full = char_array\n",
    "y_train_full = text_array\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "output_len = 0x7F - 0x21\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\", input_shape=[v_max_size, h_max_size, 1]),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(output_len, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(\n",
    "#     loss=keras.losses.sparse_categorical_crossentropy,\n",
    "#     optimizer=keras.optimizers.SGD(),\n",
    "#     metrics=[keras.metrics.sparse_categorical_accuracy],\n",
    "# )\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP 사용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "X_train_full = char_array\n",
    "y_train_full = text_array\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "output_len = 0x7F - 0x21\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[v_max_size, h_max_size]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(output_len, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(\n",
    "#     loss=keras.losses.sparse_categorical_crossentropy,\n",
    "#     optimizer=keras.optimizers.SGD(),\n",
    "#     metrics=[keras.metrics.sparse_categorical_accuracy],\n",
    "# )\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be683a387f613599acfa5f2904ea86e105e419b0abf42dde19e0d0b9b1440bd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
